{
    "directory_tree": "[FILE] .pre-commit-config.yaml\n[FILE] CONTRIBUTING.md\n[FILE] llmify_config.yaml\n[FILE] README.md\n[FILE] requirements.txt\n[DIR]  src\n    [DIR]  extractor\n        [FILE] init.py\n        [FILE] llm_code_prep.py\n[DIR]  tests\n    [FILE] test_extractor.py\n",
    "files": [
        {
            "filename": "C:\\Users\\Estudiante\\Downloads\\LLMify-Code\\.pre-commit-config.yaml",
            "content": "repos:\n  - repo: https://github.com/PyCQA/pylint\n    rev: stable\n    hooks:\n      - id: pylint\n",
            "token_count": 31
        },
        {
            "filename": "C:\\Users\\Estudiante\\Downloads\\LLMify-Code\\CONTRIBUTING.md",
            "content": "# Contributing to LLMify-Code\n\nThank you for your interest in contributing to **LLMify-Code**! We welcome contributions that improve the project, fix bugs, or enhance its features. This document outlines the guidelines for contributing to ensure a smooth collaboration process.\n\n---\n\n## Table of Contents\n\n- [How to Contribute](#how-to-contribute)\n- [Reporting Bugs](#reporting-bugs)\n- [Suggesting Enhancements](#suggesting-enhancements)\n- [Pull Request Process](#pull-request-process)\n- [Coding Guidelines](#coding-guidelines)\n- [Commit Messages](#commit-messages)\n- [License](#license)\n\n---\n\n## How to Contribute\n\nContributions to LLMify-Code can take many forms, including:\n\n- **Bug Reports:** If you encounter any bugs, please check the [issue tracker](https://github.com/yourusername/LLMify-Code/issues) before opening a new issue.\n- **Enhancements:** If you have suggestions for new features or improvements, please open an issue first to discuss your idea.\n- **Code Contributions:** Fork the repository, make your changes, and submit a pull request. Ensure your changes adhere to the coding guidelines below.\n- **Documentation:** Contributions to improve or update documentation, including this file, are always welcome.\n\n---\n\n## Reporting Bugs\n\nWhen reporting a bug, please include:\n\n- A **clear description** of the problem.\n- **Steps to reproduce** the issue.\n- The **expected behavior** and what actually happened.\n- Information about your **environment** (OS, Python version, etc.).\n- Any relevant **logs or screenshots**.\n\nPlease open an issue in the [issue tracker](https://github.com/yourusername/LLMify-Code/issues).\n\n---\n\n## Suggesting Enhancements\n\nIf you have an idea for a new feature or an improvement:\n\n1. **Search** the existing issues to ensure it hasn\u2019t already been suggested.\n2. **Open a new issue** describing your idea in detail.\n3. If you are comfortable with coding, consider opening a pull request with your proposed changes after discussing the idea.\n\n---\n\n## Pull Request Process\n\nBefore submitting a pull request (PR), please follow these steps:\n\n1. **Fork** the repository and create your branch from `main`.\n2. **Ensure** that your branch is up-to-date with the latest code.\n3. **Write tests** for your changes, if applicable.\n4. **Run all tests** to ensure nothing is broken.\n5. **Document your changes** thoroughly.\n6. **Submit a pull request** describing your changes, referencing any related issues.\n\nA good PR description should include:\n- **Context:** What problem does this PR address?\n- **Solution:** How does the PR solve the problem?\n- **Testing:** How have you tested the changes?\n- **Impact:** Any potential impacts or backward-incompatible changes.\n\n---\n\n## Coding Guidelines\n\nTo maintain code quality, please adhere to the following guidelines:\n\n- **Code Style:** Follow [PEP 8](https://www.python.org/dev/peps/pep-0008/).\n- **Documentation:** Write clear docstrings for functions and classes.\n- **Testing:** Include unit tests for new functionality. Use `pytest` for running tests.\n- **Linting:** Run [Pylint](https://pylint.org/) before submitting your code to ensure it meets our standards.\n\n---\n\n## Commit Messages\n\nPlease use clear and descriptive commit messages. Here\u2019s a suggested format:\n\n- **Title:** A short summary (less than 50 characters).\n- **Body (optional):** A detailed description of what and why.\n- **Footer (optional):** References to any related issues (e.g., \"Fixes #123\").\n\nExample:\n\n```\nImprove token counting error handling\n\nAdded specific exception handling for tokenization errors to prevent crashes\nwhen tiktoken encounters unexpected input. This fixes issue #45.\n```\n\n---\n\n## License\n\nBy contributing to LLMify-Code, you agree that your contributions will be licensed under the project's [MIT License](LICENSE).\n\n---\n\n## Final Note\n\nWe appreciate your contributions and thank you for helping to make LLMify-Code better for everyone. If you have any questions or need guidance, please feel free to reach out via the issue tracker or contact the maintainers directly.\n\nHappy coding!\n",
            "token_count": 896
        },
        {
            "filename": "C:\\Users\\Estudiante\\Downloads\\LLMify-Code\\llmify_config.yaml",
            "content": "# llmify_config.yaml\n# This configuration file allows you to customize ignore rules for LLMify-Code.\n\nignored_dirs:\n  - .github\n  - .pytest_cache\n  - .pytest_cache/v\n  - .pytest_cache/v/cache\n  - .venv\n  - venv\n  - __pycache__\n\nignored_files:\n  - .pylintrc\n  - .gitignore\n  - codebase.txt\n  - codebase.json\n  - \"*.pyc\"\n  - \"*.pyd\"\n  - \"*.so\"\n  - \"CACHEDIR.TAG\"\n",
            "token_count": 124
        },
        {
            "filename": "C:\\Users\\Estudiante\\Downloads\\LLMify-Code\\README.md",
            "content": "# LLMify-Code\n\n**LLMify-Code** is a lightweight Python tool that transforms your local codebase into a single, well-structured text file\u2014ready to be ingested by large language models like ChatGPT. The tool extracts the entire directory tree and file contents (with robust handling of encoding issues) and optionally counts tokens using tiktoken. Output can be generated in plain text or JSON format.\n\n## Features\n\n- **Enhanced CLI Experience:**  \n  Built with [Typer](https://typer.tiangolo.com/) for a modern, user-friendly command-line interface.\n\n- **Rich Terminal Output:**  \n  Uses [Rich](https://rich.readthedocs.io/) to display attractive log messages.\n\n- **Hardcoded Ignore Rules:**  \n  Predefined ignore rules prevent unwanted directories (e.g. `node_modules`, `logs`, `config`, `.venv`, `venv`, `__pycache__`) and files (e.g. `package-lock.json`, `yarn.lock`, `.env`, `*.pyc`, `*.pyd`, `*.so`, `.pylintrc`, `.gitignore`, `codebase.txt`) from being included in the output.\n\n- **Output Format Options:**  \n  Choose between plain text output (default) and JSON output (which includes the directory tree, file metadata, and token counts).\n\n- **Tokenization Support:**  \n  Optionally count tokens (using [tiktoken](https://github.com/openai/tiktoken)) in the output.\n\n- **Robust File Reading:**  \n  Files are read with error replacement to avoid Unicode decoding issues.\n\n## Repository Structure\n\n```\nLLMify-Code/\n\u251c\u2500\u2500 .github/                   # GitHub workflows and related files\n\u251c\u2500\u2500 .pytest_cache/             # Cache for pytest runs\n\u251c\u2500\u2500 .venv/                     # Virtual environment directory (hidden)\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 extractor/\n\u2502       \u251c\u2500\u2500 __init__.py        # Package initializer for extractor\n\u2502       \u2514\u2500\u2500 llm_code_prep.py   # Main extraction script\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 test_extractor.py      # Unit tests for the extraction tool\n\u251c\u2500\u2500 venv/                      # (Alternate) Virtual environment directory\n\u251c\u2500\u2500 .gitignore                 # Files/directories to be ignored by Git\n\u251c\u2500\u2500 .pre-commit-config.yaml    # Pre-commit hook configuration\n\u251c\u2500\u2500 .pylintrc                  # Pylint configuration\n\u251c\u2500\u2500 codebase.txt               # Example output file (generated)\n\u251c\u2500\u2500 CONTRIBUTING.md            # Contribution guidelines\n\u251c\u2500\u2500 llmify_config.yaml         # YAML configuration for ignore rules\n\u251c\u2500\u2500 README.md                  # This documentation file\n\u2514\u2500\u2500 requirements.txt           # Required Python packages with version numbers\n```\n\n## Installation\n\n1. **Clone the Repository:**\n\n   ```bash\n   git clone https://github.com/yourusername/LLMify-Code.git\n   cd LLMify-Code\n   ```\n\n2. **(Optional) Create a Virtual Environment:**\n\n   ```bash\n   python -m venv venv\n   source venv/bin/activate   # On Windows: venv\\Scripts\\activate\n   ```\n\n3. **Install Dependencies:**\n\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n## Usage\n\nRun LLMify-Code using one of the following commands (from the project root):\n\n1. **Basic Extraction (Plain Text Output)**\n   ```bash\n   python -m extractor.llm_code_prep --directory . --output codebase.txt\n   ```\n   *Extracts the codebase from the current directory and writes a plain text output to `codebase.txt`.*\n\n2. **Extraction with JSON Output**\n   ```bash\n   python -m extractor.llm_code_prep --directory . --output codebase.json --output-format json\n   ```\n   *Extracts the codebase and writes a JSON output (including the directory tree, file metadata, and token counts) to `codebase.json`.*\n\n3. **Extraction with Tokenization Enabled**\n   ```bash\n   python -m extractor.llm_code_prep --directory . --output codebase.txt --tokenize\n   ```\n   *Extracts the codebase in plain text format and displays the total token count using tiktoken.*\n\n> **Note:** The script writes the directory tree and file contents directly into the output file and does not display the tree on the terminal.\n\n## Configuration\n\nLLMify-Code uses hardcoded ignore rules. The current rules are:\n\n- **Ignored Directories:**\n  - `node_modules`\n  - `logs`\n  - `config`\n  - `.venv`\n  - `venv`\n  - `__pycache__`\n\n- **Ignored Files:**\n  - `package-lock.json`\n  - `yarn.lock`\n  - `.env`\n  - `*.pyc`\n  - `*.pyd`\n  - `*.so`\n  - `.pylintrc`\n  - `.gitignore`\n  - `codebase.txt`\n\n> **Tip:** If you want to include or exclude additional files, you can update the hardcoded rules in `src/extractor/llm_code_prep.py`.\n\n## Testing\n\nUnit tests are provided in the `tests/` directory. To run the tests, simply execute:\n\n```bash\npytest\n```\n\n## Contributing\n\nContributions are welcome! Please follow these guidelines:\n\n- Fork the repository and create your feature branch.\n- Write tests for new features.\n- Ensure your code adheres to [PEP 8](https://www.python.org/dev/peps/pep-0008/) standards.\n- Open a pull request with a clear description of your changes.\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for detailed instructions.\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n\n## Contact\n\nFor questions or suggestions, please open an issue on GitHub or contact [your.email@example.com](mailto:your.email@example.com).\n\n---\n\n**LLMify-Code** \u2013 Making your code LLM-ready, one file at a time!\n\nHappy Coding!\n",
            "token_count": 1294
        },
        {
            "filename": "C:\\Users\\Estudiante\\Downloads\\LLMify-Code\\requirements.txt",
            "content": "typer>=0.9\nrich>=13.5\ntiktoken>=0.5\nruamel.yaml>=0.17\npytest>=8.0\npylint>=3.3\n",
            "token_count": 42
        },
        {
            "filename": "C:\\Users\\Estudiante\\Downloads\\LLMify-Code\\src\\extractor\\init.py",
            "content": "\"\"\"\nLLMify-Code Extractor Package\n\nThis package contains modules for extracting a codebase into a single text file,\ncomplete with a filtered directory listing, optional tokenization, and support\nfor configuration via YAML.\n\"\"\"\n",
            "token_count": 45
        },
        {
            "filename": "C:\\Users\\Estudiante\\Downloads\\LLMify-Code\\src\\extractor\\llm_code_prep.py",
            "content": "#!/usr/bin/env python\n\"\"\"\nllm_code_prep.py\n\nA tool to extract a codebase by generating a filtered directory listing and\naggregating source code from files into a single output file. Optionally, it can\ncount tokens using tiktoken and output results in JSON format with metadata.\n\nFeatures:\n- Loads ignore rules from a YAML configuration file located in the project root.\n- Provides output in plain text (default) or JSON format.\n- Optionally counts tokens for the extracted output.\n\nUsage Examples:\n  1. Plain text extraction:\n     python -m extractor.llm_code_prep --directory . --output codebase.txt\n  2. JSON extraction:\n     python -m extractor.llm_code_prep --directory . --output codebase.json --output-format json\n  3. Extraction with token count:\n     python -m extractor.llm_code_prep --directory . --output codebase.txt --tokenize\n\"\"\"\n\nimport os\nimport json\nimport logging\nfrom typing import Optional, Dict, Any, Tuple\n\nimport typer\nfrom rich.console import Console\nfrom ruamel.yaml import YAML, YAMLError\n\ntry:\n    import tiktoken\nexcept ImportError:\n    tiktoken = None  # Tokenization will be disabled if tiktoken is not installed\n\napp = typer.Typer()\nconsole = Console()\n\ndef load_config(config_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Loads a YAML configuration file for custom ignore rules.\n    If the file is missing or empty, fallback to empty ignore lists.\n\n    Parameters:\n        config_path (str): Path to the YAML configuration file.\n\n    Returns:\n        dict: Configuration dictionary containing 'ignored_dirs' and 'ignored_files'.\n    \"\"\"\n    try:\n        yaml = YAML(typ=\"safe\")\n        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n            config = yaml.load(f) or {}\n        console.log(\"[green]Configuration loaded from %s.[/green]\", config_path)\n        return config\n    except (FileNotFoundError, PermissionError, YAMLError) as e:\n        console.log(\"[yellow]Could not load config file %s: %s. No ignore rules applied.[/yellow]\", config_path, e)\n        return {\"ignored_dirs\": [], \"ignored_files\": []}\n\ndef merge_ignore_rules(config: Dict[str, Any]) -> Tuple[set, set]:\n    \"\"\"\n    Converts configuration lists for ignored directories and files into sets.\n\n    Parameters:\n        config (dict): Configuration dictionary with keys 'ignored_dirs' and 'ignored_files'.\n\n    Returns:\n        tuple: (ignored_dirs, ignored_files) as sets.\n    \"\"\"\n    ignored_dirs = set(config.get(\"ignored_dirs\", []))\n    ignored_files = set(config.get(\"ignored_files\", []))\n    return ignored_dirs, ignored_files\n\ndef get_directory_tree(\n    directory: str, ignored_dirs: set, ignored_files: set, indent: str = \"\"\n) -> str:\n    \"\"\"\n    Recursively builds a string representing the directory tree,\n    filtering out ignored directories and files.\n\n    Parameters:\n        directory (str): The target directory.\n        ignored_dirs (set): Set of directory names to ignore.\n        ignored_files (set): Set of file names to ignore.\n        indent (str): Indentation for nested items.\n\n    Returns:\n        str: The formatted directory tree.\n    \"\"\"\n    tree_str = \"\"\n    try:\n        entries = sorted(os.scandir(directory), key=lambda e: e.name.lower())\n    except OSError as e:\n        logging.error(\"Error scanning directory %s: %s\", directory, e)\n        return \"\"\n    \n    for entry in entries:\n        if entry.is_dir():\n            if entry.name not in ignored_dirs:\n                tree_str += f\"{indent}[DIR]  {entry.name}\\n\"\n                tree_str += get_directory_tree(\n                    os.path.join(directory, entry.name),\n                    ignored_dirs,\n                    ignored_files,\n                    indent + \"    \"\n                )\n        elif entry.is_file():\n            if entry.name not in ignored_files:\n                tree_str += f\"{indent}[FILE] {entry.name}\\n\"\n    return tree_str\n\ndef extract_code_text(\n    directory: str, output_file: str, ignored_dirs: set, ignored_files: set\n) -> None:\n    \"\"\"\n    Extracts the directory tree and file contents into a plain text output file.\n\n    Parameters:\n        directory (str): The target directory.\n        output_file (str): Output file name.\n        ignored_dirs (set): Set of directories to ignore.\n        ignored_files (set): Set of files to ignore.\n    \"\"\"\n    with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n        out_file.write(\"=== Directory Listing ===\\n\\n\")\n        tree = get_directory_tree(directory, ignored_dirs, ignored_files)\n        out_file.write(tree)\n        out_file.write(\"\\n=== End of Directory Listing ===\\n\\n\")\n        for root, dirs, files in os.walk(directory):\n            # Filter out ignored directories by their basename\n            dirs[:] = [d for d in dirs if d not in ignored_dirs]\n            for file in files:\n                if file in ignored_files or file.endswith((\".exe\", \".dll\", \".bin\")):\n                    continue\n                file_path = os.path.join(root, file)\n                try:\n                    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                        content = f.read()\n                    out_file.write(f\"### FILE: {file_path}\\n\")\n                    out_file.write(content + \"\\n\\n\")\n                except OSError as e:\n                    logging.warning(\"Skipping %s: %s\", file_path, e)\n    console.log(\"[bold green]\u2705 Code extracted successfully into %s[/bold green]\", output_file)\n\ndef extract_code_json(\n    directory: str, output_file: str, ignored_dirs: set, ignored_files: set\n) -> None:\n    \"\"\"\n    Extracts the directory tree and file contents into a JSON output file with metadata.\n    The JSON includes the directory tree, file metadata (including token counts if available),\n    and the total token count.\n\n    Parameters:\n        directory (str): The target directory.\n        output_file (str): Output file name.\n        ignored_dirs (set): Set of directories to ignore.\n        ignored_files (set): Set of files to ignore.\n    \"\"\"\n    data = {}\n    data[\"directory_tree\"] = get_directory_tree(directory, ignored_dirs, ignored_files)\n    data[\"files\"] = []\n    total_tokens = 0\n    for root, dirs, files in os.walk(directory):\n        dirs[:] = [d for d in dirs if d not in ignored_dirs]\n        for file in files:\n            if file in ignored_files or file.endswith((\".exe\", \".dll\", \".bin\")):\n                continue\n            file_path = os.path.join(root, file)\n            try:\n                with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                    content = f.read()\n                file_data = {\"filename\": file_path, \"content\": content}\n                token_count = count_tokens_in_text(content)\n                if token_count is not None:\n                    file_data[\"token_count\"] = token_count\n                    total_tokens += token_count\n                data[\"files\"].append(file_data)\n            except OSError as e:\n                logging.warning(\"Skipping %s: %s\", file_path, e)\n    data[\"total_tokens\"] = total_tokens\n    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n        json.dump(data, f, indent=4)\n    console.log(\"[bold green]\u2705 JSON output generated successfully into %s[/bold green]\", output_file)\n\ndef count_tokens_in_text(text: str, model: str = \"gpt-4\") -> Optional[int]:\n    \"\"\"\n    Counts tokens in the given text using tiktoken, if available.\n\n    Parameters:\n        text (str): The text to tokenize.\n        model (str): Target model for tokenization (default: 'gpt-4').\n\n    Returns:\n        Optional[int]: The number of tokens, or None if tiktoken is not installed\n                       or an error occurs.\n    \"\"\"\n    if not tiktoken:\n        console.log(\"[yellow]Tokenization is disabled because tiktoken is not installed.[/yellow]\")\n        return None\n    try:\n        enc = tiktoken.encoding_for_model(model)\n        tokens = enc.encode(text)\n        return len(tokens)\n    except (ValueError, RuntimeError) as e:\n        logging.error(\"Error during tokenization: %s\", e)\n        return None\n\n@app.command()\ndef extract(\n    directory: str = typer.Option(os.getcwd(), \"--directory\", \"-d\",\n                                  help=\"Target directory to extract.\"),\n    output: str = typer.Option(\"codebase.txt\", \"--output\", \"-o\",\n                               help=\"Output file name.\"),\n    output_format: str = typer.Option(\"text\", \"--output-format\", \"-f\",\n                                      help=\"Output format: 'text' or 'json'.\",\n                                      show_default=True),\n    tokenize: bool = typer.Option(False, \"--tokenize\", \"-t\",\n                                  help=\"Display token count for the output.\")\n):\n    \"\"\"\n    Extract the codebase from the given directory and output it in text or JSON format.\n    Optionally, count tokens for the output.\n\n    Command-line Options:\n        --directory (-d): Target directory to extract from.\n        --output (-o): Output file name.\n        --output-format (-f): Format of the output file ('text' or 'json').\n        --tokenize (-t): If set, counts tokens in the final output.\n    \"\"\"\n    abs_directory = os.path.abspath(directory)\n    console.log(\"[blue]Target directory:[/blue] %s\", abs_directory)\n\n    # Load ignore rules from YAML configuration file (located in the project root).\n    config_path = \"llmify_config.yaml\"\n    config_data = load_config(config_path)\n    ignored_dirs, ignored_files = merge_ignore_rules(config_data)\n\n    if not typer.confirm(\"Proceed with code extraction?\"):\n        console.log(\"[red]Extraction cancelled by user.[/red]\")\n        raise typer.Exit()\n\n    if output_format.lower() == \"json\":\n        extract_code_json(abs_directory, output, ignored_dirs, ignored_files)\n    else:\n        extract_code_text(abs_directory, output, ignored_dirs, ignored_files)\n\n    if tokenize:\n        try:\n            with open(output, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                content = f.read()\n            token_count = count_tokens_in_text(content)\n            if token_count is not None:\n                console.log(\"[green]Total token count:[/green] %s\", token_count)\n        except OSError as e:\n            logging.error(\"Error reading output file for tokenization: %s\", e)\n\ndef main():\n    \"\"\"\n    Main entry point for the LLMify-Code extraction tool.\n    \"\"\"\n    app()\n\nif __name__ == \"__main__\":\n    main()\n",
            "token_count": 2270
        },
        {
            "filename": "C:\\Users\\Estudiante\\Downloads\\LLMify-Code\\tests\\test_extractor.py",
            "content": "\"\"\"\ntest_extractor.py\n\nThis module contains unit tests for the `llm_code_prep` script.\nIt tests the functionality of:\n- Generating a directory tree while respecting ignored directories/files.\n- Extracting a JSON representation of the codebase.\n- Counting tokens in a text using `tiktoken` if available.\n\nEach test creates a temporary directory and files, ensuring that the tests are\nisolated and do not depend on an actual codebase.\n\nUsage:\n    Run pytest to execute all tests.\n\"\"\"\nimport os\nimport tempfile\nimport shutil\nimport json\nfrom extractor import llm_code_prep\n\ndef create_sample_directory(base_dir: str) -> None:\n    \"\"\"\n    Create a sample directory structure for testing.\n\n    The structure includes:\n      - A subdirectory 'src' containing a sample file.\n      - A directory 'node_modules' that should be ignored.\n      - A sample file 'file1.txt' in the base directory.\n      - An ignored file 'llm_code_prep.py' in the base directory.\n    \"\"\"\n    os.makedirs(os.path.join(base_dir, \"src\"), exist_ok=True)\n    os.makedirs(os.path.join(base_dir, \"node_modules\"), exist_ok=True)  # Should be ignored\n\n    # Create a valid file in the base directory.\n    with open(os.path.join(base_dir, \"file1.txt\"), \"w\", encoding=\"utf-8\") as f:\n        f.write(\"Content of file1\")\n\n    # Create a valid file in the 'src' subdirectory.\n    with open(os.path.join(base_dir, \"src\", \"file2.txt\"), \"w\", encoding=\"utf-8\") as f:\n        f.write(\"Content of file2\")\n\n    # Create an ignored file in the base directory.\n    with open(os.path.join(base_dir, \"llm_code_prep.py\"), \"w\", encoding=\"utf-8\") as f:\n        f.write(\"This file should be ignored.\")\n\ndef test_get_directory_tree() -> None:\n    \"\"\"\n    Test that the directory tree is generated correctly\n    and that ignored directories and files are excluded.\n\n    Expected behavior:\n      - 'node_modules' and 'llm_code_prep.py' should not appear in the output.\n      - 'file1.txt' and 'file2.txt' should be present.\n    \"\"\"\n    temp_dir = tempfile.mkdtemp()\n    try:\n        create_sample_directory(temp_dir)\n\n        # Define ignored rules matching the ones used in the application.\n        ignored_dirs = {\"node_modules\"}\n        ignored_files = {\"llm_code_prep.py\"}\n\n        # Generate the directory tree.\n        tree = llm_code_prep.get_directory_tree(temp_dir, ignored_dirs, ignored_files)\n\n        # Verify that the ignored directory and file are not in the tree.\n        assert \"node_modules\" not in tree\n        assert \"llm_code_prep.py\" not in tree\n\n        # Verify that valid files are listed.\n        assert \"file1.txt\" in tree\n        assert \"file2.txt\" in tree\n    finally:\n        shutil.rmtree(temp_dir)\n\ndef test_json_output() -> None:\n    \"\"\"\n    Test that the JSON output is generated correctly.\n\n    The JSON should include:\n      - A 'directory_tree' key with the generated directory tree.\n      - A 'files' key that is a list containing metadata for each file.\n      - A 'total_tokens' key representing the total token count.\n    Additionally, files in ignored directories or with ignored names should not appear.\n    \"\"\"\n    temp_dir = tempfile.mkdtemp()\n    output_file = os.path.join(temp_dir, \"output.json\")\n    try:\n        create_sample_directory(temp_dir)\n\n        # Define ignored rules.\n        ignored_dirs = {\"node_modules\"}\n        ignored_files = {\"llm_code_prep.py\"}\n\n        # Generate JSON output.\n        llm_code_prep.extract_code_json(temp_dir, output_file, ignored_dirs, ignored_files)\n\n        # Load the JSON file.\n        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n            data = json.load(f)\n\n        # Check that required keys are present.\n        assert \"directory_tree\" in data\n        assert \"files\" in data\n        assert \"total_tokens\" in data\n\n        # Ensure that ignored files/directories are not present.\n        for file_info in data[\"files\"]:\n            assert \"node_modules\" not in file_info[\"filename\"]\n            assert \"llm_code_prep.py\" not in file_info[\"filename\"]\n\n    finally:\n        shutil.rmtree(temp_dir)\n\ndef test_token_count() -> None:\n    \"\"\"\n    Test the token counting functionality.\n\n    This test verifies that the function 'count_tokens_in_text' returns an integer\n    greater than zero when tiktoken is installed, or None otherwise.\n    \"\"\"\n    sample_text = \"Hello, world! This is a test.\"\n    token_count = llm_code_prep.count_tokens_in_text(sample_text, model=\"gpt-4\")\n\n    # If token_count is available, it should be an integer greater than zero.\n    if token_count is not None:\n        assert isinstance(token_count, int)\n        assert token_count > 0\n\nif __name__ == \"__main__\":\n    test_get_directory_tree()\n    test_json_output()\n    test_token_count()\n",
            "token_count": 1074
        }
    ],
    "total_tokens": 5776
}